{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 03**: Neural Networks\n",
    "\n",
    "**Name**: D.M.S.P.Dissanayaka  \n",
    "**Index Number**: 210141U  \n",
    "**GitHub**: [Link](https://github.com/SahanDissanayaka/Image-Processing-and-Computer-Vision/blob/main/Assignments/Assignment3/assignment3.ipynb)\n",
    "\n",
    "**Date**: 13.11.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"text-align: center; font-size: 20px;\">\n",
    "Problem 01\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1 / 10, Loss: 1.9288332643508912\n",
      "Epoch 2 / 10, Loss: 1.7058271461725234\n",
      "Epoch 3 / 10, Loss: 1.625243411540985\n",
      "Epoch 4 / 10, Loss: 1.5621463190317153\n",
      "Epoch 5 / 10, Loss: 1.5055618959665298\n",
      "Epoch 6 / 10, Loss: 1.4573044549226761\n",
      "Epoch 7 / 10, Loss: 1.4167438144683837\n",
      "Epoch 8 / 10, Loss: 1.3773663821220399\n",
      "Epoch 9 / 10, Loss: 1.3444280259013175\n",
      "Epoch 10 / 10, Loss: 1.3141039056181907\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 55.36%\n",
      "Test accuracy: 48.39%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataloading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 50\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model parameters\n",
    "Din = 3 * 32 * 32  # Input size (flattened CIFAR-10 image size)\n",
    "H = 100  # Hidden layer size\n",
    "K = 10  # Output size (number of classes in CIFAR-10)\n",
    "std = 1e-5\n",
    "# Initialize weights and biases\n",
    "w1 = torch.randn(Din, H) * std  # Input to hidden layer weights\n",
    "b1 = torch.zeros(H)  # Hidden layer bias\n",
    "w2 = torch.randn(H, K) * std  # Hidden to output layer weights\n",
    "b2 = torch.zeros(K)  # Output layer bias\n",
    "\n",
    "# Hyperparameters\n",
    "iterations = 10\n",
    "lr = 2e-1\n",
    "lr_decay = 0.9\n",
    "reg = 0  # Regularization\n",
    "loss_history = []\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Training Loop\n",
    "for t in range(iterations):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]  # Batch size\n",
    "        x_train = inputs.view(Ntr, -1)  # Flatten input to (Ntr, Din)\n",
    "\n",
    "        # Forward pass\n",
    "        hidden_layer = sigmoid(x_train.mm(w1) + b1)  # Hidden layer activation\n",
    "        logits = hidden_layer.mm(w2) + b2  # Output layer logits\n",
    "\n",
    "        # Cross-entropy loss with regularization\n",
    "        loss = nn.functional.cross_entropy(logits, labels) + reg * (torch.sum(w1 ** 2) + torch.sum(w2 ** 2))\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        # Compute gradients for output layer\n",
    "        dy_pred = nn.functional.softmax(logits, dim=1)  # Softmax predictions\n",
    "        dy_pred[range(Ntr), labels] -= 1  # Compute gradient wrt logits\n",
    "        dy_pred /= Ntr  # Normalize gradient by batch size\n",
    "\n",
    "        dw2 = hidden_layer.t().mm(dy_pred) + reg * w2\n",
    "        db2 = dy_pred.sum(dim=0)\n",
    "\n",
    "        # Compute gradients for hidden layer\n",
    "        dhidden = dy_pred.mm(w2.t()) * (hidden_layer * (1 - hidden_layer))\n",
    "        dw1 = x_train.t().mm(dhidden) + reg * w1\n",
    "        db1 = dhidden.sum(dim=0)\n",
    "\n",
    "        # Parameter update\n",
    "        w1 -= lr * dw1\n",
    "        b1 -= lr * db1\n",
    "        w2 -= lr * dw2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "    loss_history.append(loss.item())\n",
    "    # Print loss for every epoch\n",
    "    if t % 1 == 0:\n",
    "        print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "    # Learning rate decay\n",
    "    lr *= lr_decay\n",
    "\n",
    "# Plotting the Loss History\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Loss History\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Accuracy on Training Set\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]\n",
    "        x_train = inputs.view(Ntr, -1)\n",
    "        hidden_layer = sigmoid(x_train.mm(w1) + b1)\n",
    "        logits_train = hidden_layer.mm(w2) + b2\n",
    "        predicted_train = torch.argmax(logits_train, dim=1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "train_acc = 100 * correct_train / total_train\n",
    "print(f\"Training accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Calculate Accuracy on Test Set\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        Nte = inputs.shape[0]\n",
    "        x_test = inputs.view(Nte, -1)\n",
    "        hidden_layer = sigmoid(x_test.mm(w1) + b1)\n",
    "        logits_test = hidden_layer.mm(w2) + b2\n",
    "        predicted_test = torch.argmax(logits_test, dim=1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted_test == labels).sum().item()\n",
    "test_acc = 100 * correct_test / total_test\n",
    "print(f\"Test accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"text-align: center; font-size: 20px;\">\n",
    "Problem 02\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) # output: 6x28x28\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)               # output: 6x14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)                      # output: 16x10x10\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)                # output: 16x5x5\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)          # No activation here; CrossEntropyLoss applies softmax\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Accuracy: 90.54%, Test Accuracy: 97.41%\n",
      "Epoch [2/10], Training Accuracy: 97.47%, Test Accuracy: 98.44%\n",
      "Epoch [3/10], Training Accuracy: 98.24%, Test Accuracy: 98.05%\n",
      "Epoch [4/10], Training Accuracy: 98.64%, Test Accuracy: 98.93%\n",
      "Epoch [5/10], Training Accuracy: 98.80%, Test Accuracy: 98.80%\n",
      "Epoch [6/10], Training Accuracy: 99.01%, Test Accuracy: 98.78%\n",
      "Epoch [7/10], Training Accuracy: 99.15%, Test Accuracy: 99.07%\n",
      "Epoch [8/10], Training Accuracy: 99.24%, Test Accuracy: 99.13%\n",
      "Epoch [9/10], Training Accuracy: 99.39%, Test Accuracy: 99.17%\n",
      "Epoch [10/10], Training Accuracy: 99.44%, Test Accuracy: 99.02%\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_test += predicted.eq(labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "    \n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"text-align: center; font-size: 20px;\">\n",
    "Problem 03\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"text-align: center; font-size: 20px;\">\n",
    "Setup\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 20px;\">\n",
    "(a) Fine Tuning the Model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# Load ResNet18 with the new weights parameter\n",
    "model_ft = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  # Or use `weights=ResNet18_Weights.DEFAULT`\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)  # Modify the final layer for 2 classes\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.6434\n",
      "val Loss: 0.2858 Acc: 0.8889\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.4725 Acc: 0.8197\n",
      "val Loss: 0.2779 Acc: 0.8627\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3917 Acc: 0.8361\n",
      "val Loss: 0.2002 Acc: 0.9150\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5620 Acc: 0.7623\n",
      "val Loss: 0.3424 Acc: 0.8693\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4731 Acc: 0.8279\n",
      "val Loss: 0.3485 Acc: 0.8693\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.6799 Acc: 0.7787\n",
      "val Loss: 0.4780 Acc: 0.8366\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.6104 Acc: 0.7951\n",
      "val Loss: 0.2822 Acc: 0.8824\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4045 Acc: 0.8361\n",
      "val Loss: 0.2309 Acc: 0.9216\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3078 Acc: 0.8770\n",
      "val Loss: 0.1929 Acc: 0.9412\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3549 Acc: 0.8525\n",
      "val Loss: 0.2410 Acc: 0.9150\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3929 Acc: 0.8320\n",
      "val Loss: 0.1964 Acc: 0.9412\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3134 Acc: 0.8811\n",
      "val Loss: 0.2335 Acc: 0.9150\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3454 Acc: 0.8443\n",
      "val Loss: 0.2015 Acc: 0.9542\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3369 Acc: 0.8566\n",
      "val Loss: 0.2131 Acc: 0.9477\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3835 Acc: 0.8484\n",
      "val Loss: 0.2059 Acc: 0.9477\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2857 Acc: 0.8852\n",
      "val Loss: 0.2080 Acc: 0.9412\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2595 Acc: 0.8770\n",
      "val Loss: 0.2174 Acc: 0.9412\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3029 Acc: 0.8730\n",
      "val Loss: 0.2230 Acc: 0.9346\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2171 Acc: 0.9057\n",
      "val Loss: 0.2163 Acc: 0.9412\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2712 Acc: 0.9016\n",
      "val Loss: 0.2275 Acc: 0.9412\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3156 Acc: 0.8607\n",
      "val Loss: 0.2370 Acc: 0.9085\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3223 Acc: 0.8525\n",
      "val Loss: 0.2090 Acc: 0.9542\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2707 Acc: 0.8852\n",
      "val Loss: 0.2130 Acc: 0.9412\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2378 Acc: 0.9016\n",
      "val Loss: 0.2112 Acc: 0.9477\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3034 Acc: 0.8689\n",
      "val Loss: 0.2534 Acc: 0.9150\n",
      "Training complete in 13m 9s\n",
      "Best val Acc: 0.9542\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Update the learning rate scheduler after each training epoch\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # Save the best model weights based on validation accuracy\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 20px;\">\n",
    "(b) Using the Network as a Feature Extractor\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6949 Acc: 0.6066\n",
      "val Loss: 0.4392 Acc: 0.8105\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5755 Acc: 0.7254\n",
      "val Loss: 0.1767 Acc: 0.9542\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4413 Acc: 0.8238\n",
      "val Loss: 0.2484 Acc: 0.9150\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4381 Acc: 0.8033\n",
      "val Loss: 0.2091 Acc: 0.9477\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4643 Acc: 0.7787\n",
      "val Loss: 0.2752 Acc: 0.8889\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4913 Acc: 0.8033\n",
      "val Loss: 0.2047 Acc: 0.9346\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4014 Acc: 0.8074\n",
      "val Loss: 0.2388 Acc: 0.9216\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3477 Acc: 0.8525\n",
      "val Loss: 0.1879 Acc: 0.9608\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3233 Acc: 0.8484\n",
      "val Loss: 0.1862 Acc: 0.9542\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3153 Acc: 0.8443\n",
      "val Loss: 0.1866 Acc: 0.9608\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.4349 Acc: 0.8238\n",
      "val Loss: 0.2234 Acc: 0.9216\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3121 Acc: 0.8566\n",
      "val Loss: 0.1846 Acc: 0.9608\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3588 Acc: 0.8443\n",
      "val Loss: 0.1905 Acc: 0.9542\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.4196 Acc: 0.8074\n",
      "val Loss: 0.2137 Acc: 0.9477\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2818 Acc: 0.8730\n",
      "val Loss: 0.1907 Acc: 0.9477\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3226 Acc: 0.8443\n",
      "val Loss: 0.2140 Acc: 0.9281\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3342 Acc: 0.8607\n",
      "val Loss: 0.2250 Acc: 0.9412\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2615 Acc: 0.8770\n",
      "val Loss: 0.1986 Acc: 0.9412\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3405 Acc: 0.8566\n",
      "val Loss: 0.1957 Acc: 0.9412\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2977 Acc: 0.8566\n",
      "val Loss: 0.1896 Acc: 0.9542\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2958 Acc: 0.8770\n",
      "val Loss: 0.2063 Acc: 0.9346\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3346 Acc: 0.8484\n",
      "val Loss: 0.1821 Acc: 0.9608\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3534 Acc: 0.8607\n",
      "val Loss: 0.2057 Acc: 0.9412\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3329 Acc: 0.8402\n",
      "val Loss: 0.1932 Acc: 0.9542\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3757 Acc: 0.8484\n",
      "val Loss: 0.1790 Acc: 0.9608\n",
      "Training complete in 8m 31s\n",
      "Best val Acc: 0.9608\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet18 with the updated weights parameter\n",
    "model_conv = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  # Or use `weights=ResNet18_Weights.DEFAULT`\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer to have 2 output features (for 2 classes: ants and bees)\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define an optimizer that only updates the parameters of the final layer\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 20px;\">\n",
    "Reporting the Results\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Results:\n",
      "Validation Accuracy: 0.9542\n",
      "\n",
      "Feature Extraction Results:\n",
      "Validation Accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            corrects += torch.sum(preds == labels)\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = corrects.double() / total\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(\"Fine-tuning Results:\")\n",
    "evaluate_model(model_ft)\n",
    "\n",
    "print(\"\\nFeature Extraction Results:\")\n",
    "evaluate_model(model_conv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
