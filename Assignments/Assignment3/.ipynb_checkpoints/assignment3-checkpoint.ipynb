{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EN3160 Image Processing and Machine Vision\n",
    "## Assignment 03: Neural Networks\n",
    "### Name :- D.M.S.P.Dissanayaka\n",
    "### Index Number :- 210141U\n",
    "### Date :- 12.11.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1 / 10, Loss: 2.3025855596065523\n",
      "Epoch 2 / 10, Loss: 2.302585515499115\n",
      "Epoch 3 / 10, Loss: 2.302585478544235\n",
      "Epoch 4 / 10, Loss: 2.3025854258537293\n",
      "Epoch 5 / 10, Loss: 2.3025853888988497\n",
      "Epoch 6 / 10, Loss: 2.3025853562355043\n",
      "Epoch 7 / 10, Loss: 2.3025853385925292\n",
      "Epoch 8 / 10, Loss: 2.302585308790207\n",
      "Epoch 9 / 10, Loss: 2.3025852875709534\n",
      "Epoch 10 / 10, Loss: 2.302585267782211\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 10.00%\n",
      "Test accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataloading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 50\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model parameters\n",
    "Din = 3 * 32 * 32  # Input size (flattened CIFAR-10 image size)\n",
    "H = 100  # Hidden layer size\n",
    "K = 10  # Output size (number of classes in CIFAR-10)\n",
    "std = 1e-5\n",
    "# Initialize weights and biases\n",
    "w1 = torch.randn(Din, H) * std  # Input to hidden layer weights\n",
    "b1 = torch.zeros(H)  # Hidden layer bias\n",
    "w2 = torch.randn(H, K) * std  # Hidden to output layer weights\n",
    "b2 = torch.zeros(K)  # Output layer bias\n",
    "\n",
    "# Hyperparameters\n",
    "iterations = 10\n",
    "lr = 2e-6\n",
    "lr_decay = 0.9\n",
    "reg = 0  # Regularization\n",
    "loss_history = []\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Training Loop\n",
    "for t in range(iterations):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]  # Batch size\n",
    "        x_train = inputs.view(Ntr, -1)  # Flatten input to (Ntr, Din)\n",
    "\n",
    "        # Forward pass\n",
    "        hidden_layer = sigmoid(x_train.mm(w1) + b1)  # Hidden layer activation\n",
    "        logits = hidden_layer.mm(w2) + b2  # Output layer logits\n",
    "\n",
    "        # Cross-entropy loss with regularization\n",
    "        loss = nn.functional.cross_entropy(logits, labels) + reg * (torch.sum(w1 ** 2) + torch.sum(w2 ** 2))\n",
    "        loss_history.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        # Compute gradients for output layer\n",
    "        dy_pred = nn.functional.softmax(logits, dim=1)  # Softmax predictions\n",
    "        dy_pred[range(Ntr), labels] -= 1  # Compute gradient wrt logits\n",
    "        dy_pred /= Ntr  # Normalize gradient by batch size\n",
    "\n",
    "        dw2 = hidden_layer.t().mm(dy_pred) + reg * w2\n",
    "        db2 = dy_pred.sum(dim=0)\n",
    "\n",
    "        # Compute gradients for hidden layer\n",
    "        dhidden = dy_pred.mm(w2.t()) * (hidden_layer * (1 - hidden_layer))\n",
    "        dw1 = x_train.t().mm(dhidden) + reg * w1\n",
    "        db1 = dhidden.sum(dim=0)\n",
    "\n",
    "        # Parameter update\n",
    "        w1 -= lr * dw1\n",
    "        b1 -= lr * db1\n",
    "        w2 -= lr * dw2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    if t % 1 == 0:\n",
    "        print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "    # Learning rate decay\n",
    "    lr *= lr_decay\n",
    "\n",
    "# Plotting the Loss History\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Loss History\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Accuracy on Training Set\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]\n",
    "        x_train = inputs.view(Ntr, -1)\n",
    "        hidden_layer = sigmoid(x_train.mm(w1) + b1)\n",
    "        logits_train = hidden_layer.mm(w2) + b2\n",
    "        predicted_train = torch.argmax(logits_train, dim=1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "train_acc = 100 * correct_train / total_train\n",
    "print(f\"Training accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Calculate Accuracy on Test Set\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        Nte = inputs.shape[0]\n",
    "        x_test = inputs.view(Nte, -1)\n",
    "        hidden_layer = sigmoid(x_test.mm(w1) + b1)\n",
    "        logits_test = hidden_layer.mm(w2) + b2\n",
    "        predicted_test = torch.argmax(logits_test, dim=1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted_test == labels).sum().item()\n",
    "test_acc = 100 * correct_test / total_test\n",
    "print(f\"Test accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) # output: 6x28x28\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)               # output: 6x14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)                      # output: 16x10x10\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)                # output: 16x5x5\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)          # No activation here; CrossEntropyLoss applies softmax\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Accuracy: 90.11%, Test Accuracy: 96.99%\n",
      "Epoch [2/10], Training Accuracy: 97.34%, Test Accuracy: 97.66%\n",
      "Epoch [3/10], Training Accuracy: 98.08%, Test Accuracy: 98.66%\n",
      "Epoch [4/10], Training Accuracy: 98.50%, Test Accuracy: 98.72%\n",
      "Epoch [5/10], Training Accuracy: 98.72%, Test Accuracy: 98.85%\n",
      "Epoch [6/10], Training Accuracy: 98.89%, Test Accuracy: 98.84%\n",
      "Epoch [7/10], Training Accuracy: 98.97%, Test Accuracy: 98.61%\n",
      "Epoch [8/10], Training Accuracy: 99.15%, Test Accuracy: 98.87%\n",
      "Epoch [9/10], Training Accuracy: 99.27%, Test Accuracy: 98.87%\n",
      "Epoch [10/10], Training Accuracy: 99.36%, Test Accuracy: 99.05%\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_test += predicted.eq(labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "    \n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 03: ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Sahan/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [11:35<00:00, 67.3kB/s]  \n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4925 Acc: 0.7090\n",
      "val Loss: 0.2639 Acc: 0.8954\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.4558 Acc: 0.8279\n",
      "val Loss: 0.2204 Acc: 0.8954\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4806 Acc: 0.7828\n",
      "val Loss: 0.2296 Acc: 0.9085\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.6721 Acc: 0.7459\n",
      "val Loss: 0.8336 Acc: 0.7778\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.5252 Acc: 0.8074\n",
      "val Loss: 0.2700 Acc: 0.8824\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4277 Acc: 0.8238\n",
      "val Loss: 0.2740 Acc: 0.8954\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3343 Acc: 0.8402\n",
      "val Loss: 0.2341 Acc: 0.9085\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3306 Acc: 0.8402\n",
      "val Loss: 0.2362 Acc: 0.9150\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3321 Acc: 0.8852\n",
      "val Loss: 0.2260 Acc: 0.9150\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3391 Acc: 0.8689\n",
      "val Loss: 0.2123 Acc: 0.9150\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3815 Acc: 0.8443\n",
      "val Loss: 0.2041 Acc: 0.9216\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2509 Acc: 0.8852\n",
      "val Loss: 0.2078 Acc: 0.9216\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3279 Acc: 0.8402\n",
      "val Loss: 0.2098 Acc: 0.9281\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3052 Acc: 0.8770\n",
      "val Loss: 0.2107 Acc: 0.9150\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9385\n",
      "val Loss: 0.2066 Acc: 0.9216\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3207 Acc: 0.8648\n",
      "val Loss: 0.1977 Acc: 0.9216\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2866 Acc: 0.9057\n",
      "val Loss: 0.1970 Acc: 0.9216\n",
      "Epoch 17/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(best_model_wts)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 51\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     18\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     19\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 21\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\multiprocessing\\connection.py:1084\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m   1081\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m   1082\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1084\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\multiprocessing\\connection.py:1016\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m   1014\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m-> 1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3071 Acc: 0.8730\n",
      "val Loss: 0.1998 Acc: 0.9281\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2384 Acc: 0.9016\n",
      "val Loss: 0.1875 Acc: 0.9281\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2806 Acc: 0.8770\n",
      "val Loss: 0.2066 Acc: 0.9346\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2642 Acc: 0.8730\n",
      "val Loss: 0.2643 Acc: 0.9020\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2610 Acc: 0.8893\n",
      "val Loss: 0.1908 Acc: 0.9216\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2355 Acc: 0.9098\n",
      "val Loss: 0.2019 Acc: 0.9150\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2671 Acc: 0.8975\n",
      "val Loss: 0.2028 Acc: 0.9281\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2914 Acc: 0.8730\n",
      "val Loss: 0.2178 Acc: 0.9085\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2855 Acc: 0.8893\n",
      "val Loss: 0.1838 Acc: 0.9216\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2299 Acc: 0.8975\n",
      "val Loss: 0.1911 Acc: 0.9216\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2753 Acc: 0.8852\n",
      "val Loss: 0.2416 Acc: 0.9150\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2527 Acc: 0.9057\n",
      "val Loss: 0.2092 Acc: 0.9281\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3171 Acc: 0.8607\n",
      "val Loss: 0.2077 Acc: 0.9216\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2367 Acc: 0.9057\n",
      "val Loss: 0.2335 Acc: 0.9020\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3503 Acc: 0.8443\n",
      "val Loss: 0.2012 Acc: 0.9216\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3730 Acc: 0.8279\n",
      "val Loss: 0.2009 Acc: 0.9346\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2407 Acc: 0.8811\n",
      "val Loss: 0.1957 Acc: 0.9216\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2661 Acc: 0.8934\n",
      "val Loss: 0.1831 Acc: 0.9281\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2529 Acc: 0.8852\n",
      "val Loss: 0.2168 Acc: 0.9216\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3046 Acc: 0.8443\n",
      "val Loss: 0.2111 Acc: 0.9216\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2982 Acc: 0.8730\n",
      "val Loss: 0.1866 Acc: 0.9346\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3076 Acc: 0.8770\n",
      "val Loss: 0.1857 Acc: 0.9281\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2947 Acc: 0.8607\n",
      "val Loss: 0.1901 Acc: 0.9150\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2322 Acc: 0.9221\n",
      "val Loss: 0.1875 Acc: 0.9346\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2964 Acc: 0.8484\n",
      "val Loss: 0.2022 Acc: 0.9281\n",
      "Training complete in 13m 16s\n",
      "Best val Acc: 0.9346\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Update the learning rate scheduler after each training epoch\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # Save the best model weights based on validation accuracy\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Using the Network as a Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7300 Acc: 0.6189\n",
      "val Loss: 0.2248 Acc: 0.9281\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.4742 Acc: 0.7664\n",
      "val Loss: 0.2215 Acc: 0.9216\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5219 Acc: 0.7664\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4515 Acc: 0.7951\n",
      "val Loss: 0.2862 Acc: 0.8693\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3532 Acc: 0.8566\n",
      "val Loss: 0.1550 Acc: 0.9542\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.5410 Acc: 0.7992\n",
      "val Loss: 0.2602 Acc: 0.8954\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3736 Acc: 0.8607\n",
      "val Loss: 0.2584 Acc: 0.9216\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4620 Acc: 0.8074\n",
      "val Loss: 0.1888 Acc: 0.9477\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3563 Acc: 0.8361\n",
      "val Loss: 0.1903 Acc: 0.9412\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3134 Acc: 0.8361\n",
      "val Loss: 0.1799 Acc: 0.9412\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3243 Acc: 0.8566\n",
      "val Loss: 0.2020 Acc: 0.9477\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3576 Acc: 0.8320\n",
      "val Loss: 0.2074 Acc: 0.9477\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3538 Acc: 0.8402\n",
      "val Loss: 0.1872 Acc: 0.9412\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.4048 Acc: 0.8443\n",
      "val Loss: 0.1757 Acc: 0.9477\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.4721 Acc: 0.7951\n",
      "val Loss: 0.1876 Acc: 0.9412\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3491 Acc: 0.8443\n",
      "val Loss: 0.1684 Acc: 0.9477\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3615 Acc: 0.8402\n",
      "val Loss: 0.1802 Acc: 0.9477\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3609 Acc: 0.8525\n",
      "val Loss: 0.1768 Acc: 0.9477\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2522 Acc: 0.9016\n",
      "val Loss: 0.1891 Acc: 0.9477\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3037 Acc: 0.8648\n",
      "val Loss: 0.1851 Acc: 0.9412\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3577 Acc: 0.8443\n",
      "val Loss: 0.1796 Acc: 0.9477\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.4302 Acc: 0.7992\n",
      "val Loss: 0.1847 Acc: 0.9477\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3073 Acc: 0.8770\n",
      "val Loss: 0.1702 Acc: 0.9412\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3123 Acc: 0.8607\n",
      "val Loss: 0.2108 Acc: 0.9477\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3512 Acc: 0.8197\n",
      "val Loss: 0.2084 Acc: 0.9412\n",
      "Training complete in 8m 47s\n",
      "Best val Acc: 0.9542\n"
     ]
    }
   ],
   "source": [
    "model_conv = models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Results:\n",
      "Validation Accuracy: 0.9346\n",
      "\n",
      "Feature Extraction Results:\n",
      "Validation Accuracy: 0.9542\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            corrects += torch.sum(preds == labels)\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = corrects.double() / total\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(\"Fine-tuning Results:\")\n",
    "evaluate_model(model_ft)\n",
    "\n",
    "print(\"\\nFeature Extraction Results:\")\n",
    "evaluate_model(model_conv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
